README FILE

1)	Data Ingestion
Short FAQ Documents were made by collecting the Frequent asked Questions from company like
Flipkart  -> Ecommerce Company.
Physics Wallah  -> Educational Company.
Jio -> Telecommunication Company.

2)	Vector Store & Retrieval 
•	Due to dependencies error. I created a Python 3.10 virtual environment to ensure compatibility with HuggingFace and LangChain libraries
And Then I installed all the necessary Libraries.
•	Then Used unstructuredWordDocumnetLoader from langchain_community_loaders
•	Splits the documents into smaller chunks to better retrieval granularity
•	Built a FAISS index to store embeddings.
•	Implemented a retrieval function to fetch top relevant documents chunks.
3)	LLM Integration 
•	Connected a Large-language model to enhance the document based answers.
•	Query is passed to LLM (Hugging face) for generation of final answer.
•	OpenAi API is costly that’s the reason to use LLM
4)	Agentic Workflow
•	Implement a keyword based agent router in agent.py to simulate decision-making logic -:
If the query include the keyword calculate. It is then routed to calculator
If the query includes define, It uses dictionary API’s to fetch definition
All the other query follow the standard RAG based- path via RAG pipeline.
5)	Streamlit UI
Streamlit is used in making the CLI for the Pipeline where Query can be written and its Result is generated by the LLM.
File Structure
rag_system/
    ── app.py (for Streamlit UI)
    ── agents.py
    ── llm.py
    ── tools.py
    ── requirments.txt
    ─ FAQ_FLIPKART.docx

HOW TO RUN THE CODE

Unzip the folder and open the terminal and run the first command
1) pip install -r requirments.txt

And the after all the requirements are installed run the streamlit CLI provided here
2) streamlit run app.py --server.runOnSave false

You will see the UI Like this

 
While Claculating or defining anything 
Always use lowercase letters

calculate 80+20
Define jump


 

There is also a log file in the folder which strors all the Input given the Query box.
